server:
  ingress:
    enabled: true
    hosts:
    - prometheus.dockerflow.com
    annotations:
      kubernetes.io/tls-acme: "true"
    tls:
    - hosts:
      - prometheus.dockerflow.com
      secretName: letsencrypt-secret-prometheus
  resources:
    limits:
      cpu: 100m
      memory: 1500Mi
    requests:
      cpu: 50m
      memory: 1000Mi
alertmanager:
  ingress:
    enabled: true
    hosts:
    - alertmanager.dockerflow.com
    annotations:
      kubernetes.io/tls-acme: "true"
    tls:
    - hosts:
      - alertmanager.dockerflow.com
      secretName: letsencrypt-secret-alertmanager
  resources:
    limits:
      cpu: 10m
      memory: 20Mi
    requests:
      cpu: 5m
      memory: 10Mi
kubeStateMetrics:
  resources:
    limits:
      cpu: 10m
      memory: 50Mi
    requests:
      cpu: 5m
      memory: 25Mi
nodeExporter:
  resources:
    limits:
      cpu: 10m
      memory: 20Mi
    requests:
      cpu: 5m
      memory: 10Mi
pushgateway:
  resources:
    limits:
      cpu: 10m
      memory: 20Mi
    requests:
      cpu: 5m
      memory: 10Mi
serverFiles:
  alerts:
    groups:
    - name: nodes
      rules:
      - alert: TooManyNodes
        expr: count(kube_node_info) > 3
        for: 15m
        labels:
          severity: notify
        annotations:
          summary: Cluster increased
          description: The number of the nodes in the cluster increased
      - alert: TooFewNodes
        expr: count(kube_node_info) < 3
        for: 15m
        labels:
          severity: notify
        annotations:
          summary: Cluster decreased
          description: The number of the nodes in the cluster decreased
    - name: pods
      rules:
      - alert: ProblematicPods
        expr: sum(kube_pod_status_phase{phase=~"Failed|Unknown|Pending"}) by (phase) > 0
        for: 15m
        labels:
          severity: notify
        annotations:
          summary: Problems with Pods
          description: At least one Pod is in a problematic phase
      - alert: OldPods
        expr: (time() - kube_pod_start_time{namespace!="kube-system"}) > (60 * 60 * 24 * 90)
        labels:
          severity: notify
          frequency: low
        annotations:
          summary: Old Pods
          description: At least one Pod has not be updated to more than 90 days
      - alert: ReservedMemTooLow
        expr: sum(label_join(container_memory_usage_bytes{namespace!="kube-system"}, "pod", ",", "pod_name")) by (pod) / sum(kube_pod_container_resource_requests_memory_bytes{namespace!="kube-system"}) by (pod) > 1.25
        for: 1h
        labels:
          severity: notify
          frequency: low
        annotations:
          summary: Reserved memory is too low
          description: At least one Pod uses much more memory than it reserved
      - alert: ReservedMemTooHigh
        expr: sum(label_join(container_memory_usage_bytes{namespace!="kube-system"}, "pod", ",", "pod_name")) by (pod) / sum(kube_pod_container_resource_requests_memory_bytes{namespace!="kube-system"}) by (pod) < 0.6
        for: 6h
        labels:
          severity: notify
          frequency: low
        annotations:
          summary: Reserved memory is too high
          description: At least one Pod uses much less memory than it reserved
alertmanagerFiles:
  alertmanager.yml:
    global: {}
    route:
      group_wait: 10s
      group_interval: 5m
      receiver: slack
      repeat_interval: 3h
      routes:
      - receiver: slack
        repeat_interval: 5d
        match:
          severity: notify
          frequency: low
    receivers:
    - name: slack
      slack_configs:
      - api_url: SLACK_WEBHOOK_URL
        send_resolved: true
        title: "{{ .CommonAnnotations.summary }}"
        text: "{{ .CommonAnnotations.description }}"
        title_link: https://prometheus.dockerflow.com/alerts
